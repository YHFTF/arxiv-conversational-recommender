# llm_topic_classifier.py
# -------------------------------------------------------
# Classify OGBN-Arxiv paper abstracts into arXiv CS categories (cs.xx)
# Output: JSON with label_idx, category, reasoning
# -------------------------------------------------------

import os
import json
import random
import sys
import torch
import pandas as pd
import numpy as np
from openai import OpenAI
import time


client = OpenAI(api_key=os.environ["OPENAI_API_KEY"])
GLOBAL_START = time.time()

# -------------------------------------------------------
# 0. Path Configuration
# -------------------------------------------------------
FFS_LOAD_FILE = "ogbn_arxiv_16k_ffs_sample.pt"
NODE_TO_ID_MAP_PATH = "dataset/ogbn_arxiv/mapping/nodeidx2paperid.csv"
TITLEABS_TSV_PATH = "titleabs.tsv"
LABEL_MAPPING_PATH = "dataset/ogbn_arxiv/mapping/labelidx2arxivcategeory.csv.gz"

SAMPLE_COUNT = 100
OUTPUT_JSON_FILE = "topic_prediction_results.json"

LLM_MODEL = "gpt-4o-mini"
SIMULATION_MODE = False

# -------------------------------------------------------
# 1. Fix torch.load for PyTorch 2.6 security change
# -------------------------------------------------------
_real_torch_load = torch.load

def _torch_load_with_weights_only_false(*args, **kwargs):
    if "weights_only" not in kwargs:
        kwargs["weights_only"] = False
    return _real_torch_load(*args, **kwargs)


torch.load = _torch_load_with_weights_only_false


# -------------------------------------------------------
# 2. Load FFS sample node indices (+ labels)
# -------------------------------------------------------

def load_sample_nodes_and_labels(path):
    if not os.path.exists(path):
        print(f"â›” ERROR: {path} not found. Run main_sampler.py first.")
        sys.exit(1)
    data = torch.load(path)

    indices = data["indices"]               # 16,000ê°œ ë…¸ë“œ ì¸ë±ìŠ¤ (ë¦¬ìŠ¤íŠ¸)
    labels_tensor = data["labels"].squeeze()  # (16000,) í…ì„œë¼ê³  ê°€ì •

    # node_index -> label_idx ë¡œ ë§¤í•‘
    node_to_label = {
        int(node_idx): int(labels_tensor[i].item())
        for i, node_idx in enumerate(indices)
    }
    return indices, node_to_label


print("ğŸ“Œ Loading FFS sample file...")
sampled_nodes, node_to_label = load_sample_nodes_and_labels(FFS_LOAD_FILE)

# ìƒ˜í”Œë§
target_indices = random.sample(sampled_nodes, SAMPLE_COUNT)
print(f"âœ… Sampled {len(target_indices)} nodes.\n")


# -------------------------------------------------------
# 3. Load node â†’ paper_id mapping
# -------------------------------------------------------

def load_node_to_paperid_map(path):
    try:
        df = pd.read_csv(path, header=0, dtype={"idx": np.int32, "paper id": str})
        return df["paper id"].tolist()
    except Exception as e:
        print("â›” Mapping load error:", e)
        sys.exit(1)


node_id_list = load_node_to_paperid_map(NODE_TO_ID_MAP_PATH)
print("ğŸ“Œ Node-to-paperID mapping loaded.\n")


# -------------------------------------------------------
# 4. Load titles & abstracts from TSV
# -------------------------------------------------------

def extract_title_abstracts(tsv_path, node_id_list, target_idx_list):
    df = pd.read_csv(
        tsv_path,
        sep="\t",
        header=None,
        names=["paper id", "title", "abstract"],
        dtype={"paper id": str},
    ).set_index("paper id")

    title_abs_list = []
    for idx in target_idx_list:
        pid = node_id_list[idx]
        if pid not in df.index:
            title_abs_list.append(("ERROR: TITLE NOT FOUND", "ERROR: ABSTRACT NOT FOUND"))
        else:
            row = df.loc[pid]
            title = row["title"]
            abstract = row["abstract"]
            if isinstance(abstract, str):
                abstract = abstract.replace("Abstract", "", 1).strip()
            title_abs_list.append((title, abstract))
    return title_abs_list


title_abs_texts = extract_title_abstracts(TITLEABS_TSV_PATH, node_id_list, target_indices)
print("ğŸ“Œ Extracted titles & abstracts.\n")


# -------------------------------------------------------
# 5. Load label â†’ arxiv category mapping
# -------------------------------------------------------

def load_label_mapping(path):
    df = pd.read_csv(path, compression="gzip")
    return df["arxiv category"].tolist()


category_list = load_label_mapping(LABEL_MAPPING_PATH)
print(f"ğŸ“Œ Loaded {len(category_list)} arXiv categories.\n")

# -------------------------------------------------------
# 5-1. arXiv CS ì¹´í…Œê³ ë¦¬ ì„¤ëª… (í•„ìš”ì‹œ ììœ ë¡­ê²Œ ìˆ˜ì •/ì¶”ê°€)
# -------------------------------------------------------

CATEGORY_DESCRIPTIONS = {
    # arxiv cs na â€“ ìˆ˜ì¹˜í•´ì„ (cs.NA)
    # ìˆ˜ì¹˜ ì•Œê³ ë¦¬ì¦˜, ê³¼í•™/ê³µí•™ ê³„ì‚°, ë¶€ë™ì†Œìˆ˜ì  ì˜¤ì°¨ ë¶„ì„ ë“±
    "arxiv cs na": "Numerical Analysis (cs.NA): numerical algorithms, scientific computing, floating-point error analysis.",

    # arxiv cs mm â€“ ë©€í‹°ë¯¸ë””ì–´ (cs.MM)
    # ì˜¤ë””ì˜¤/ë¹„ë””ì˜¤, ë©€í‹°ë¯¸ë””ì–´ ì²˜ë¦¬ ë° ìƒì„±, ë©€í‹°ëª¨ë‹¬ ì½˜í…ì¸ 
    "arxiv cs mm": "Multimedia (cs.MM): audio, video, and multimodal content analysis and generation.",

    # arxiv cs lo â€“ ì»´í“¨í„°ê³¼í•™ì˜ ë…¼ë¦¬ (cs.LO)
    # í˜•ì‹ ë…¼ë¦¬, ê²€ì¦, ì¦ëª… ì´ë¡ , ì •í˜• ê¸°ë²•
    "arxiv cs lo": "Logic in Computer Science (cs.LO): formal methods, verification, proof theory, logical systems.",

    # arxiv cs cy â€“ ì»´í“¨í„°ì™€ ì‚¬íšŒ (cs.CY)
    # ICTì™€ ì‚¬íšŒ ì˜í–¥, í”„ë¼ì´ë²„ì‹œ, ìœ¤ë¦¬, ì •ì±…, ë””ì§€í„¸ ì‚¬íšŒ
    "arxiv cs cy": "Computers and Society (cs.CY): social impact of computing, policy, ethics, privacy, digital society.",

    # arxiv cs cr â€“ ì•”í˜¸ ë° ë³´ì•ˆ (cs.CR)
    # ì•”í˜¸ í”„ë¡œí† ì½œ, ê³µê²©/ë°©ì–´, í”„ë¼ì´ë²„ì‹œ, ì•ˆì „í•œ ì‹œìŠ¤í…œ
    "arxiv cs cr": "Cryptography and Security (cs.CR): cryptographic protocols, system security, privacy, secure computation.",

    # arxiv cs dc â€“ ë¶„ì‚°/ë³‘ë ¬/í´ëŸ¬ìŠ¤í„° ì»´í“¨íŒ… (cs.DC)
    # ë¶„ì‚° ì‹œìŠ¤í…œ, í´ë¼ìš°ë“œ, í•©ì˜, ë³‘ë ¬ ì²˜ë¦¬
    "arxiv cs dc": "Distributed, Parallel, and Cluster Computing (cs.DC): distributed systems, cloud, consensus, parallelism.",

    # arxiv cs hc â€“ ì¸ê°„-ì»´í“¨í„° ìƒí˜¸ì‘ìš© (cs.HC)
    # ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤, UX, ì‚¬ìš©ì„± í‰ê°€, ì¸í„°ë™ì…˜ ê¸°ë²•
    "arxiv cs hc": "Human-Computer Interaction (cs.HC): user interfaces, usability, interaction techniques, UX.",

    # arxiv cs ce â€“ ê³„ì‚° ê³µí•™/ê¸ˆìœµ/ê³¼í•™ (cs.CE)
    # ê³µí•™/ê¸ˆìœµ/ê³¼í•™ ë¶„ì•¼ì˜ ê³ ì„±ëŠ¥ ê³„ì‚° ì‘ìš©
    "arxiv cs ce": "Computational Engineering, Finance, and Science (cs.CE): high-performance computing in engineering, finance, science.",

    # arxiv cs ni â€“ ë„¤íŠ¸ì›Œí‚¹ ë° ì¸í„°ë„· ì•„í‚¤í…ì²˜ (cs.NI)
    # ë„¤íŠ¸ì›Œí¬ í”„ë¡œí† ì½œ, ë¼ìš°íŒ…, íŠ¸ë˜í”½ ì—”ì§€ë‹ˆì–´ë§, SDN
    "arxiv cs ni": "Networking and Internet Architecture (cs.NI): network protocols, routing, traffic engineering, SDN.",

    # arxiv cs cc â€“ ê³„ì‚° ë³µì¡ë„ (cs.CC)
    # ë³µì¡ë„ ê³„ì¸µ, í•˜í•œ/ìƒí•œ, íš¨ìœ¨ì„± í•œê³„
    "arxiv cs cc": "Computational Complexity (cs.CC): complexity classes, lower bounds, limits of efficient computation.",

    # arxiv cs ai â€“ ì¸ê³µì§€ëŠ¥ (cs.AI)
    # ì§€ëŠ¥í˜• ì—ì´ì „íŠ¸, ê³„íš, ì§€ì‹ í‘œí˜„, ì¶”ë¡ 
    "arxiv cs ai": "Artificial Intelligence (cs.AI): intelligent agents, planning, reasoning, knowledge representation.",

    # arxiv cs ma â€“ ë©€í‹°ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ (cs.MA)
    # ì—ì´ì „íŠ¸ ìƒí˜¸ì‘ìš©, í˜‘ë™/ê²½ìŸ, ê²Œì„ì´ë¡ ì  ë‹¤ì¤‘ ì£¼ì²´
    "arxiv cs ma": "Multiagent Systems (cs.MA): interacting agents, cooperation, negotiation, game-theoretic multi-agent settings.",

    # arxiv cs gl â€“ ì¼ë°˜ ë¬¸í—Œ (cs.GL)
    # ì»´í“¨í„°ê³¼í•™ ì „ë°˜ì— ëŒ€í•œ ì—ì„¸ì´, íŠœí† ë¦¬ì–¼, ë¦¬ë·° ë“±
    "arxiv cs gl": "General Literature (cs.GL): surveys, essays, tutorials, and general-interest computer science works.",

    # arxiv cs ne â€“ ì‹ ê²½/ì§„í™” ì»´í“¨íŒ… (cs.NE)
    # ì‹ ê²½ë§ ì´ë¡ , ì‹ ê²½ ì§„í™”, ì§„í™” ì•Œê³ ë¦¬ì¦˜
    "arxiv cs ne": "Neural and Evolutionary Computing (cs.NE): neural network theory, neuroevolution, evolutionary algorithms.",

    # arxiv cs sc â€“ ê¸°í˜¸ ê³„ì‚° (cs.SC)
    # ì‹¬ë³¼ë¦­ ì—°ì‚°, ì»´í“¨í„° ëŒ€ìˆ˜ ì‹œìŠ¤í…œ, ìˆ˜í•™ í‘œí˜„ ì¡°ì‘
    "arxiv cs sc": "Symbolic Computation (cs.SC): symbolic algebra, computer algebra systems, manipulation of mathematical expressions.",

    # arxiv cs ar â€“ í•˜ë“œì›¨ì–´ ì•„í‚¤í…ì²˜ (cs.AR)
    # í”„ë¡œì„¸ì„œ/ê°€ì†ê¸° ì„¤ê³„, ë§ˆì´í¬ë¡œì•„í‚¤í…ì²˜, ì‹œìŠ¤í…œ êµ¬ì¡°
    "arxiv cs ar": "Hardware Architecture (cs.AR): processor and accelerator design, microarchitecture, system organization.",

    # arxiv cs cv â€“ ì»´í“¨í„° ë¹„ì „ ë° íŒ¨í„´ì¸ì‹ (cs.CV)
    # ì´ë¯¸ì§€/ë¹„ë””ì˜¤ ì´í•´, ê°ì²´ íƒì§€, ë¶„í• , ì¸ì‹
    "arxiv cs cv": "Computer Vision and Pattern Recognition (cs.CV): image and video understanding, detection, segmentation.",

    # arxiv cs gr â€“ ê·¸ë˜í”½ìŠ¤ (cs.GR)
    # ë Œë”ë§, ì• ë‹ˆë©”ì´ì…˜, ê¸°í•˜ ëª¨ë¸ë§, ì‹œê°í™”
    "arxiv cs gr": "Graphics (cs.GR): rendering, animation, geometric modeling, visualization.",

    # arxiv cs et â€“ ì‹ í¥ ê¸°ìˆ  (cs.ET)
    # ìƒˆë¡­ê±°ë‚˜ ë¹„ì „í†µì ì¸ ì»´í“¨íŒ… ê¸°ìˆ , ì‹¤í—˜ì  ì‹œìŠ¤í…œ
    "arxiv cs et": "Emerging Technologies (cs.ET): novel or unconventional computing technologies and experimental systems.",

    # arxiv cs sy â€“ ì‹œìŠ¤í…œ ë° ì œì–´ (cs.SY)
    # ì œì–´ ì´ë¡ , ë™ì  ì‹œìŠ¤í…œ, ì‚¬ì´ë²„-ë¬¼ë¦¬ ì‹œìŠ¤í…œ
    "arxiv cs sy": "Systems and Control (cs.SY): control theory, dynamical systems, cyber-physical systems.",

    # arxiv cs cg â€“ ê³„ì‚° ê¸°í•˜ (cs.CG)
    # ê¸°í•˜ ì•Œê³ ë¦¬ì¦˜, ê³µê°„ ë°ì´í„° êµ¬ì¡°, ê¸°í•˜ì  ê³„ì‚°
    "arxiv cs cg": "Computational Geometry (cs.CG): geometric algorithms, spatial data structures, geometric computation.",

    # arxiv cs oh â€“ ê¸°íƒ€ ì»´í“¨í„°ê³¼í•™ (cs.OH)
    # ê¸°ì¡´ ì¹´í…Œê³ ë¦¬ì— ì˜ ë§ì§€ ì•ŠëŠ” ê¸°íƒ€ CS ì£¼ì œ
    "arxiv cs oh": "Other Computer Science (cs.OH): computer science topics not covered by other specific categories.",

    # arxiv cs pl â€“ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ (cs.PL)
    # ì–¸ì–´ ì„¤ê³„, íƒ€ì… ì‹œìŠ¤í…œ, ì»´íŒŒì¼ëŸ¬, ì •ì  ë¶„ì„
    "arxiv cs pl": "Programming Languages (cs.PL): language design, type systems, compilers, static analysis.",

    # arxiv cs se â€“ ì†Œí”„íŠ¸ì›¨ì–´ ê³µí•™ (cs.SE)
    # ìš”êµ¬ë¶„ì„, ì„¤ê³„, í…ŒìŠ¤íŠ¸, ìœ ì§€ë³´ìˆ˜, ê°œë°œ í”„ë¡œì„¸ìŠ¤
    "arxiv cs se": "Software Engineering (cs.SE): software design, testing, maintenance, development processes and tools.",

    # arxiv cs lg â€“ ë¨¸ì‹ ëŸ¬ë‹ (cs.LG)
    # ì§€ë„/ë¹„ì§€ë„/ê°•í™”í•™ìŠµ, ë”¥ëŸ¬ë‹, í‘œí˜„ í•™ìŠµ
    "arxiv cs lg": "Machine Learning (cs.LG): supervised, unsupervised, and reinforcement learning, deep and representation learning.",

    # arxiv cs sd â€“ ì‚¬ìš´ë“œ (cs.SD)
    # ì˜¤ë””ì˜¤ ì‹ í˜¸ ì²˜ë¦¬, ìŒí–¥ ëª¨ë¸ë§, ìŒì•… ì •ë³´ ì²˜ë¦¬
    "arxiv cs sd": "Sound (cs.SD): audio signal processing, acoustics, music information retrieval.",

    # arxiv cs si â€“ ì‚¬íšŒ/ì •ë³´ ë„¤íŠ¸ì›Œí¬ (cs.SI)
    # ì†Œì…œ ë„¤íŠ¸ì›Œí¬ ë¶„ì„, ê·¸ë˜í”„ ë§ˆì´ë‹, ì˜¨ë¼ì¸ ê´€ê³„ë§
    "arxiv cs si": "Social and Information Networks (cs.SI): social network analysis, graph mining, online communities.",

    # arxiv cs ro â€“ ë¡œë³´í‹±ìŠ¤ (cs.RO)
    # ë¡œë´‡ ì œì–´, ì§€ê°, ë‚´ë¹„ê²Œì´ì…˜, ë§¤ë‹ˆí“°ë ˆì´ì…˜
    "arxiv cs ro": "Robotics (cs.RO): robot control, perception, navigation, and manipulation.",

    # arxiv cs it â€“ ì •ë³´ ì´ë¡  (cs.IT)
    # ì •ë³´ëŸ‰, ì±„ë„ ìš©ëŸ‰, ë¶€í˜¸ ì´ë¡ , ì••ì¶•
    "arxiv cs it": "Information Theory (cs.IT): information measures, channel capacity, coding theory, compression.",

    # arxiv cs pf â€“ ì„±ëŠ¥ (cs.PF)
    # ì‹œìŠ¤í…œ/ë„¤íŠ¸ì›Œí¬/ì• í”Œë¦¬ì¼€ì´ì…˜ ì„±ëŠ¥ ë¶„ì„ ë° ëª¨ë¸ë§
    "arxiv cs pf": "Performance (cs.PF): performance evaluation, benchmarking, and modeling of systems and networks.",

    # arxiv cs cl â€“ ê³„ì‚°ê³¼ ì–¸ì–´ (cs.CL, ìì—°ì–´ì²˜ë¦¬)
    # ìì—°ì–´ ì²˜ë¦¬, ë²ˆì—­, ì–¸ì–´ ëª¨ë¸, ëŒ€í™” ì‹œìŠ¤í…œ
    "arxiv cs cl": "Computation and Language (cs.CL): natural language processing, translation, language models, dialogue.",

    # arxiv cs ir â€“ ì •ë³´ ê²€ìƒ‰ (cs.IR)
    # ê²€ìƒ‰ì—”ì§„, ë­í‚¹, ì§ˆì˜ í™•ì¥, ì¶”ì²œ
    "arxiv cs ir": "Information Retrieval (cs.IR): search engines, ranking algorithms, retrieval models, recommendation.",

    # arxiv cs ms â€“ ìˆ˜í•™ ì†Œí”„íŠ¸ì›¨ì–´ (cs.MS)
    # ìˆ˜ì¹˜/ê¸°í˜¸ ì—°ì‚°ì„ ìœ„í•œ ìˆ˜í•™ ì†Œí”„íŠ¸ì›¨ì–´, ë¼ì´ë¸ŒëŸ¬ë¦¬
    "arxiv cs ms": "Mathematical Software (cs.MS): software and libraries for numerical or symbolic mathematical computation.",

    # arxiv cs fl â€“ í˜•ì‹ì–¸ì–´ ë° ì˜¤í† ë§ˆíƒ€ (cs.FL)
    # í˜•ì‹ ì–¸ì–´ ì´ë¡ , ì˜¤í† ë§ˆíƒ€, ë¬¸ë²•, êµ¬ë¬¸ ë¶„ì„
    "arxiv cs fl": "Formal Languages and Automata Theory (cs.FL): formal languages, automata, grammars, parsing.",

    # arxiv cs ds â€“ ë°ì´í„° êµ¬ì¡° ë° ì•Œê³ ë¦¬ì¦˜ (cs.DS)
    # ê¸°ë³¸/ê³ ê¸‰ ìë£Œêµ¬ì¡°, ì•Œê³ ë¦¬ì¦˜ ì„¤ê³„/ë¶„ì„
    "arxiv cs ds": "Data Structures and Algorithms (cs.DS): design and analysis of data structures and algorithms.",

    # arxiv cs os â€“ ìš´ì˜ì²´ì œ (cs.OS)
    # ì»¤ë„, ìŠ¤ì¼€ì¤„ë§, ë©”ëª¨ë¦¬/ìì› ê´€ë¦¬, ê°€ìƒí™”
    "arxiv cs os": "Operating Systems (cs.OS): kernels, scheduling, memory and resource management, virtualization.",

    # arxiv cs gt â€“ ê²Œì„ì´ë¡ ê³¼ ê³„ì‚° (cs.GT)
    # ì•Œê³ ë¦¬ì¦˜ì  ê²Œì„ì´ë¡ , ë©”ì»¤ë‹ˆì¦˜ ë””ìì¸, ì „ëµì  ìƒí˜¸ì‘ìš©
    "arxiv cs gt": "Computer Science and Game Theory (cs.GT): algorithmic game theory, mechanism design, strategic interaction.",

    # arxiv cs db â€“ ë°ì´í„°ë² ì´ìŠ¤ (cs.DB)
    # ë°ì´í„° ëª¨ë¸ë§, ì§ˆì˜ ì²˜ë¦¬, íŠ¸ëœì­ì…˜, ë¶„ì‚° DB
    "arxiv cs db": "Databases (cs.DB): data modeling, query processing, transactions, distributed databases.",

    # arxiv cs dl â€“ ë””ì§€í„¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ (cs.DL)
    # ë””ì§€í„¸ ì•„ì¹´ì´ë¹™, ë©”íƒ€ë°ì´í„°, ê²€ìƒ‰/íƒìƒ‰ ì„œë¹„ìŠ¤
    "arxiv cs dl": "Digital Libraries (cs.DL): digital archiving, metadata, indexing, search and access services.",

    # arxiv cs dm â€“ ì´ì‚°ìˆ˜í•™ (cs.DM)
    # ê·¸ë˜í”„ ì´ë¡ , ì¡°í•©ë¡ , ì´ì‚° êµ¬ì¡° ë° ê·¸ ì•Œê³ ë¦¬ì¦˜
    "arxiv cs dm": "Discrete Mathematics (cs.DM): graph theory, combinatorics, discrete structures and related algorithms.",
}

# -------------------------------------------------------
# 6. Create classification prompt (Title + Abstract, TOP-3)
# -------------------------------------------------------

def create_topic_prompt(title, abstract, category_list):
    category_lines = "\n".join(
        [
            f"{i}: {cat} - {CATEGORY_DESCRIPTIONS.get(cat, 'General computer science topic related to ' + cat)}"
            for i, cat in enumerate(category_list)
        ]
    )

    system_prompt = (
        "You are an AI assistant that performs single-label classification of research papers "
        "into one of the given arXiv computer science categories. "
        "Use both the title and abstract to determine the topic. "
        "You must choose exactly one category index for each candidate and you must not invent new categories. "
        "Return ONLY valid JSON, with no extra text or formatting. "
        "For each reasoning, you must paraphrase the topic and avoid reusing exact words or technical phrases "
        "from the title or abstract whenever possible. "
        "Each 'reasoning' field must About 500 words characters."
    )

    user_prompt = f"""
Title:
\"\"\"{title}\"\"\"

Abstract:
\"\"\"{abstract}\"\"\"

You must select the TOP 3 most likely categories from the list below.
Rank them from most likely (first) to less likely (third).

Category List (index: category):
{category_lines}

Output format (MUST be valid JSON only, no markdown, no explanation):

{{
  "candidates": [
    {{
      "label_idx": <integer>,
      "category": "<string>",
      "reasoning": "<explanation About 500 words characters; do not copy phrases or words from the title or abstract>"
    }},
    {{
      "label_idx": <integer>,
      "category": "<string>",
      "reasoning": "<explanation About 500 words characters; do not copy phrases or words from the title or abstract>"
    }},
    {{
      "label_idx": <integer>,
      "category": "<string>",
      "reasoning": "<explanation About 500 words characters; do not copy phrases or words from the title or abstract>"
    }}
  ]
}}
""".strip()

    return system_prompt, user_prompt

# -------------------------------------------------------
# 7. LLM Call
# -------------------------------------------------------

def call_llm_for_topic(title, abstract, model=LLM_MODEL, simulation=False):
    system_prompt, user_prompt = create_topic_prompt(title, abstract, category_list)

    if simulation:
        # ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œì¼ ë•ŒëŠ” top-1ë§Œ ëŒ€ì¶© ìƒì„±
        idx = random.randint(0, len(category_list) - 1)
        dummy = {
            "label_idx": idx,
            "category": category_list[idx],
            "reasoning": "ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ì…ë‹ˆë‹¤.",
        }
        return {
            "label_idx": dummy["label_idx"],
            "category": dummy["category"],
            "reasoning": dummy["reasoning"],
            "candidates": [dummy],  # top-1ë§Œ ë„£ì–´ë‘ 
        }, 0, 0

    try:
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
            response_format={"type": "json_object"},
            temperature=0.0,   # ë¶„ë¥˜ íƒœìŠ¤í¬ëŠ” 0 ì¶”ì²œ
            top_p=1.0,
        )

        content = response.choices[0].message.content
        raw = json.loads(content)  # {"candidates": [ {...}, {...}, {...} ]}

        candidates = raw.get("candidates", [])
        if not candidates or not isinstance(candidates, list):
            raise ValueError("LLM output does not contain a valid 'candidates' list")

        # ê°€ì¥ ê°€ëŠ¥ì„±ì´ ë†’ì€ 1ê°œ (ì²« ë²ˆì§¸)ë¥¼ ë©”ì¸ ì˜ˆì¸¡ìœ¼ë¡œ ì‚¬ìš©
        primary = candidates[0]

        result = {
            "label_idx": primary["label_idx"],
            "category": primary["category"],
            "reasoning": primary["reasoning"],
            "candidates": candidates,  # top-3 ì „ì²´ë¥¼ ê·¸ëŒ€ë¡œ ë³´ê´€
        }

        usage = response.usage
        return result, usage.prompt_tokens, usage.completion_tokens

    except Exception as e:
        print(f"â›” LLM Error: {e}")
        return None, 0, 0


# -------------------------------------------------------
# 8. Run classification for all samples
# -------------------------------------------------------
print("ğŸ“Œ Starting LLM classification...\n")

classification_start = time.time()   #  ë¶„ë¥˜ ë£¨í”„ ì‹œì‘ ì‹œê°„
total_llm_time = 0.0                 #  LLM í˜¸ì¶œì— ì†Œìš”ëœ ì´ ì‹œê°„
llm_call_count = 0                   #  ì‹¤ì œ LLM í˜¸ì¶œ íšŸìˆ˜

topic_results = []

for i, (title, abs_text) in enumerate(title_abs_texts):
    node_idx = target_indices[i]
    print(f"[{i+1}/{len(title_abs_texts)}] Processing node {node_idx}...")

    if "ERROR" in abs_text:
        print(" â†’ Abstract missing, skipping.")
        continue

    llm_start = time.time()
    result, in_tok, out_tok = call_llm_for_topic(title, abs_text, simulation=SIMULATION_MODE)
    llm_end = time.time()

    # LLM ì—ëŸ¬ ë°©ì§€
    if result is None:
        print("   â†’ LLM error, skipping.")
        continue

    total_llm_time += (llm_end - llm_start)
    llm_call_count += 1

    # ğŸ”¹ primary(pred@1) + top-3 í›„ë³´
    pred_label_idx = result["label_idx"]
    pred_category = result["category"]
    reasoning = result["reasoning"]
    candidates = result.get("candidates", [])  # [{"label_idx":..., "category":..., "reasoning":...}, ...]

    # ğŸ”¹ ì›ë˜ ë ˆì´ë¸” ì°¾ê¸°
    true_label_idx = node_to_label.get(int(node_idx), None)
    if true_label_idx is not None:
        true_category = category_list[true_label_idx]
    else:
        true_category = "UNKNOWN"

    # ğŸ”¹ ì½˜ì†”ì— ì˜ˆì¸¡ vs ì •ë‹µ ì¶œë ¥
    print(f"   â†’ Pred@1: {pred_label_idx} ({pred_category})")
    if candidates:
        # top-3 ìš”ì•½ ì¶œë ¥
        top3_str = ", ".join(
            [f"{c['label_idx']}({c['category']})" for c in candidates[:3]]
        )
        print(f"   â†’ Top-3: {top3_str}")

    if true_label_idx is not None:
        print(f"   â†’ True: {true_label_idx} ({true_category})")
        print(f"   â†’ Match@1: {pred_label_idx == true_label_idx}")
        # Top-3 ì•ˆì— ì •ë‹µì´ ìˆëŠ”ì§€
        in_top3 = any(
            (c.get("label_idx") == true_label_idx) for c in candidates[:3]
        )
        print(f"   â†’ In Top-3: {in_top3}")
    else:
        print("   â†’ True: UNKNOWN (not found in FFS label map)")

    topic_results.append({
        "node_index": node_idx,
        "title": title,
        "abstract": abs_text,
        "pred_label_idx": pred_label_idx,
        "pred_category": pred_category,
        "reasoning": reasoning,
        "topk_candidates": candidates,  # ğŸ”¹ top-3 ì „ì²´ ì €ì¥
        "true_label_idx": true_label_idx,
        "true_category": true_category,
        "is_correct_top1": (
            true_label_idx is not None and pred_label_idx == true_label_idx
        ),
        "is_correct_top3": (
            true_label_idx is not None and any(
                (c.get("label_idx") == true_label_idx) for c in candidates[:3]
            )
        ),
        "input_tokens": in_tok,
        "output_tokens": out_tok
    })

print("\nâœ… Classification completed.\n")
classification_end = time.time()

# -------------------------------------------------------
# 8.1. Compute Top-1 / Top-3 accuracy
# -------------------------------------------------------

valid_results = [r for r in topic_results if r["true_label_idx"] is not None]

if valid_results:
    total = len(valid_results)
    top1_correct = sum(1 for r in valid_results if r["is_correct_top1"])
    top3_correct = sum(1 for r in valid_results if r["is_correct_top3"])

    top1_acc = top1_correct / total
    top3_acc = top3_correct / total

    print("ğŸ“Š Evaluation summary (excluding UNKNOWN labels):")
    print(f"   â†’ Samples: {total}")
    print(f"   â†’ Top-1 accuracy: {top1_correct}/{total} ({top1_acc:.3%})")
    print(f"   â†’ Top-3 accuracy: {top3_correct}/{total} ({top3_acc:.3%})")
else:
    print("âš ï¸ No valid labels found for accuracy computation.")

# -------------------------------------------------------
# 8.2. Confusion analysis: which categories are confused?
# -------------------------------------------------------
from collections import Counter, defaultdict

# true_labelì´ ìˆëŠ” ìƒ˜í”Œë§Œ ì‚¬ìš©
valid_results = [r for r in topic_results if r["true_label_idx"] is not None]

# 1) Top-3 miss ìƒ˜í”Œ ìˆ˜ì§‘
top3_miss_samples = []
for r in valid_results:
    t_idx = r["true_label_idx"]
    top3_indices = [
        c["label_idx"]
        for c in r.get("topk_candidates", [])[:3]
        if "label_idx" in c
    ]

    if t_idx not in top3_indices:  # ğŸ”¹ Top-3 ì–´ë””ì—ë„ ì •ë‹µì´ ì—†ëŠ” ê²½ìš°
        top3_miss_samples.append(r)

total = len(valid_results)
miss_cnt = len(top3_miss_samples)
print(f"\nâŒ Top-3 miss: {miss_cnt} / {total} ({miss_cnt/total:.3%})")

# 2) Top-3 miss ìƒ˜í”Œ ëª‡ ê°œ ì˜ˆì‹œ ì¶œë ¥
print("\nğŸ“Œ Example Top-3 miss samples (up to 10):")
for r in top3_miss_samples[:10]:
    t_idx = r["true_label_idx"]
    true_cat = category_list[t_idx]
    p_idx = r["pred_label_idx"]
    pred_cat = category_list[p_idx]

    top3 = r.get("topk_candidates", [])[:3]
    top3_str = ", ".join(
        f"{c['label_idx']}({category_list[c['label_idx']]})"
        for c in top3
        if "label_idx" in c
    )

    print("-" * 80)
    print(f" True: {t_idx} ({true_cat})")
    print(f" Pred@1: {p_idx} ({pred_cat})")
    print(f" Top-3: {top3_str}")
    # ì œëª©/ì´ˆë¡ì„ ì €ì¥í•´ ë’€ë‹¤ë©´ ì•„ë˜ì²˜ëŸ¼ ê°™ì´ ë´ë„ ì¢‹ìŒ
    if "pred_title" in r:
        print(f" Title: {r['pred_title']}")
    if "pred_abstract" in r:
        print(f" Abstract: {r['pred_abstract'][:200]}...")  # ë„ˆë¬´ ê¸¸ë©´ ì•ë¶€ë¶„ë§Œ

# 3) Top-3 missì— ëŒ€í•´ì„œ (True â†’ Pred@1) í˜¼ë™ í†µê³„
pair_counter_top3_miss = Counter()
for r in top3_miss_samples:
    t_idx = r["true_label_idx"]
    p_idx = r["pred_label_idx"]
    pair_counter_top3_miss[(t_idx, p_idx)] += 1

print("\nğŸ“Š Top-3 miss confusion pairs (True â†’ Pred@1):")
for (t_idx, p_idx), cnt in pair_counter_top3_miss.most_common(20):
    true_cat = category_list[t_idx]
    pred_cat = category_list[p_idx]
    print(f" âŒ {t_idx:2d} ({true_cat})  â†’  {p_idx:2d} ({pred_cat}) : {cnt}")

# 4) ì¹´í…Œê³ ë¦¬ë³„ Top-3 miss ë¹„ìœ¨ (ì–´ë–¤ ì •ë‹µ ì¹´í…Œê³ ë¦¬ê°€ íŠ¹íˆ ì–´ë ¤ìš´ì§€)
per_class_stats = defaultdict(lambda: {"total": 0, "top3_miss": 0})

for r in valid_results:
    t_idx = r["true_label_idx"]
    per_class_stats[t_idx]["total"] += 1

for r in top3_miss_samples:
    t_idx = r["true_label_idx"]
    per_class_stats[t_idx]["top3_miss"] += 1

print("\nğŸ“Š Per-category Top-3 miss rate (by true label):")
for t_idx, stats in sorted(per_class_stats.items(), key=lambda x: x[0]):
    total_c = stats["total"]
    miss_c = stats["top3_miss"]
    if total_c == 0:
        continue
    miss_rate = miss_c / total_c
    true_cat = category_list[t_idx]
    print(f" {t_idx:2d} ({true_cat}): miss {miss_c}/{total_c} ({miss_rate:.1%})")


# -------------------------------------------------------
# 9. Save results to JSON
# -------------------------------------------------------
print(f"ğŸ“Œ Saving results â†’ {OUTPUT_JSON_FILE}")

with open(OUTPUT_JSON_FILE, "w", encoding="utf-8") as f:
    json.dump(topic_results, f, ensure_ascii=False, indent=4)

GLOBAL_END = time.time()  # â¬…ï¸ ì „ì²´ ì‹¤í–‰ ì¢…ë£Œ ì‹œê°„

print("âœ… All results saved.")
print(f"Total records: {len(topic_results)}")

# -------------------------------------------------------
# 10. Time summary
# -------------------------------------------------------
total_runtime = GLOBAL_END - GLOBAL_START
classification_runtime = classification_end - classification_start
avg_llm_time = (total_llm_time / llm_call_count) if llm_call_count > 0 else 0.0

print("\nâ±ï¸ Time summary:")
print(f"   â†’ Total runtime (script): {total_runtime:.2f} seconds")
print(f"   â†’ Classification loop:    {classification_runtime:.2f} seconds")
print(f"   â†’ LLM calls total:        {total_llm_time:.2f} seconds over {llm_call_count} calls")
print(f"   â†’ Avg time per LLM call:  {avg_llm_time:.2f} seconds")
print(f"   â†’ Avg time per sample:    {classification_runtime/len(title_abs_texts):.2f} seconds/sample")